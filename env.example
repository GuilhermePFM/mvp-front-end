# Environment Variables for Docker Compose
# Copy this file to .env and fill in your actual values

# Google Gemini API Key (required for ML classification)
# Get your key at: https://ai.google.dev/
GEMINI_API_KEY=your_gemini_api_key_here

# Encryption key for backend (required)
# Generate a secure key with: python -c "import secrets; print(secrets.token_hex(32))"
ENC_KEY=your_encryption_key_here

# Optional: Override default Gemini model
# GEMINI_MODEL=models/gemini-embedding-001

# Optional: Custom path for ML models
# MODEL_PATH=

# Port configurations (optional, defaults shown)
FRONTEND_PORT=8080
BACKEND_API_PORT=5000
EMBEDDING_API_PORT=5001

# Docker BuildKit configuration (recommended for faster builds)
# Enables pip cache persistence between builds (10-50x faster after first build)
DOCKER_BUILDKIT=1
COMPOSE_DOCKER_CLI_BUILD=1

